{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic of object detection program using OpenVINO\n",
    "\n",
    "You will learn the basic of object detection program using OpenVINO in through this exercise.\n",
    "\n",
    "Here, we'll go through a simple object detection progam using SSD(Single Shot multi-box Detection) model and learn how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required Python packages\n",
    "We'll use `matplotlib` to display image data in this exercise. Let's install `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing an input image and label text data files\n",
    "First, let's prepare imput image file and class label text file. Those files are in the OpenVINO install directory. We'll simply copy them to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/car_1.bmp .\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/inference_engine/samples/python/voc_labels.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the image file and check the picture.  \n",
    "**Note:** `IPython.display.Image` doesn't support `.bmp` format, so we use `OpenCV` and `matplotlib` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread('car_1.bmp')\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a DL model for inferencing\n",
    "Download a DL model for image classification using `Model downloader` and convert it into OpenVINO IR model with `Model converter`.  \n",
    "We'll use `googlenet-v1` model for this practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd\n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/converter.py  --name mobilenet-ssd --precisions FP16\n",
    "!ls public/mobilenet-ssd/FP16 -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "The Python inferencing code starts from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Python modules\n",
    "At first, let's import required Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork, IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading class label text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = open('voc_labels.txt').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Inference Engine core object and do some preparation\n",
    "- Create Inference Engine core object\n",
    "- Read IR model data\n",
    "- Information extraction from input and output blob (=buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Inference Engine core object\n",
    "ie = IECore()\n",
    "\n",
    "# Read an IR model data to memory\n",
    "model = './public/mobilenet-ssd/FP16/mobilenet-ssd'\n",
    "net = IENetwork(model=model+'.xml', weights=model+'.bin')\n",
    "\n",
    "# Obtain the name of the input and output blob, and input blob shape\n",
    "input_blob_name  = list(net.inputs.keys())[0]\n",
    "output_blob_name = list(net.outputs.keys())[0]\n",
    "batch,channel,height,width = net.inputs[input_blob_name].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model data to the IE core object\n",
    "Load the model data to the IE core object. The `CPU` is specified as the processor to use for infrencing job.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_net = ie.load_network(network=net, device_name='CPU', num_requests=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and manipulate input image\n",
    "Read the input image file and resize and transform it to fit it for input blob of the DL model using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input blob: name=\"{}\", N={}, C={}, H={}, W={}'.format(input_blob_name, batch, channel, height, width))\n",
    "img    = cv2.imread('car_1.bmp')\n",
    "in_img = cv2.resize(img, (width,height))\n",
    "in_img = in_img.transpose((2, 0, 1))\n",
    "in_img = in_img.reshape((1, channel, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running inference  \n",
    "The `infer()` API is a blocking function and the control will be kept waited until the inferencing task is completed.  \n",
    "Input data can be passed with a dictionary object in `{input_blob_name:input_data}` format.\n",
    "\n",
    "**IMPORTANT:** As you may have already noticed, the Python code up to this point is almost identical with the one for image classification code in the previous exercise (model, label and input image file names are the only difference). OpenVINO application is very simple and most of the code is common for different models, and only result parsing and processing code are specialized for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = exec_net.infer(inputs={input_blob_name: in_img})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the inference result  \n",
    "The `mobilenet-ssd` model outputs 100 object candidates (regardless how many objects are in a picture) and each object has 7 parameters (shape of the output blob is [1,1,100,7]).  \n",
    "The object parameter represents [`id`, `class#`, `confidence`, `xmin`, `ymin`, `xmax`, `ymax`].  \n",
    "`class#` represents class number, `confidence` means the 'likeness' to the class in value ranging from 0.0 to 1.0 (1.0=100%). (`xmin`,`ymin`)-(`xmax`,`ymax`) is the top-left and right-bottom coordination of the bounding box for the object. The coordinate is in range from 0.0 to 1.0, so, multiplies the image height and width to convert it into the pixel coordination in the picture.  \n",
    "The code checks the confidence and draw bounding box and label on the image when the confidence is higher than 0.6 (60%).\n",
    "\n",
    "Displaying the rsult image at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('output blob: name=\"{}\", shape={}'.format(output_blob_name, net.outputs[output_blob_name].shape))\n",
    "result = res[output_blob_name][0][0]\n",
    "img_h, img_w, _ = img.shape\n",
    "for obj in result:\n",
    "    imgid, clsid, confidence, x1, y1, x2, y2 = obj\n",
    "    if confidence>0.6:\n",
    "        x1 = int(x1 * img_w)\n",
    "        y1 = int(y1 * img_h)\n",
    "        x2 = int(x2 * img_w)\n",
    "        y2 = int(y2 * img_h)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,255), thickness=4 )\n",
    "        cv2.putText(img, label[int(clsid)][:-1], (x1, y1), cv2.FONT_HERSHEY_PLAIN, fontScale=4, color=(0,255,255), thickness=4)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now, you have learnt how object detection program using OpenVINO works.  \n",
    "\n",
    "As you have already saw, most of the code in the OpenVINO application is common except the result processing part.  \n",
    "What you need to know to develop an application using OpenVINO is the input and output blob format. You don't need to know the details or the internal behavior of the model to develop an application for OpenVINO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next => Basic of asynchronous inferencing - [classification-async-single.ipynb](./classification-async-single.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
